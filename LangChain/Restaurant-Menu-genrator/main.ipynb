{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "LangChain is a framework that helps developers build applications powered by large language models (LLMs), like OpenAI's GPT. It simplifies the process of connecting LLMs to external data sources, tools, and workflows, making it easier to create powerful and intelligent applications.\n",
    "\n",
    "## In Simple Words\n",
    "\n",
    "LangChain is like a \"bridge\" that connects language models (like ChatGPT) to other tools, data, or systems. It helps you use the language model to do more complex tasks, like answering questions based on your own documents, automating workflows, or even building chatbots that can interact with databases or APIs.\n",
    "\n",
    "## Key Features of LangChain\n",
    "\n",
    "- **Connects LLMs to external data**: For example, you can use LangChain to make a language model answer questions based on your own files or databases.\n",
    "- **Chains tasks together**: You can create a sequence of steps (a \"chain\") where the output of one step becomes the input for the next.\n",
    "- **Memory**: It can remember previous interactions, which is useful for building chatbots.\n",
    "- **Tools and integrations**: It works with APIs, databases, and other tools to extend the capabilities of LLMs.\n",
    "\n",
    "## Example\n",
    "\n",
    "Imagine you want to build a chatbot that can answer questions about your company's internal documents (like HR policies or FAQs). Here's how LangChain can help:\n",
    "\n",
    "1. **Load the document**: LangChain can read your company's PDF or text files.\n",
    "2. **Ask questions**: You can ask the chatbot a question like, \"What is the vacation policy?\"\n",
    "3. **Find the answer**: LangChain uses the language model to search the document and provide an accurate answer.\n",
    "4. **Chain tasks**: If the answer requires additional steps (like checking a database or sending an email), LangChain can automate those steps.\n",
    "\n",
    "## Why is LangChain Useful?\n",
    "\n",
    "Without LangChain, youâ€™d have to manually write code to connect the language model to your data or tools. LangChain simplifies this process, saving time and effort.\n",
    "\n",
    "In short, LangChain makes it easy to build smart applications using language models by connecting them to the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st  # Import the Streamlit library for creating web apps\n",
    "from langchain.llms import HuggingFaceHub  # Import the HuggingFaceHub class from LangChain for using Hugging Face models\n",
    "from langchain.prompts import PromptTemplate  # Import the PromptTemplate class from LangChain for creating prompts\n",
    "\n",
    "# Directly set your Hugging Face API token\n",
    "api_token = \"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\"  # Replace with your actual API token\n",
    "\n",
    "# Define your model repository ID\n",
    "repo_id = \"google/gemma-2-27b-it\"  # Replace with your model's repo ID\n",
    "\n",
    "# Initialize the Hugging Face model with the API token\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=api_token)\n",
    "\n",
    "# Define a function to generate restaurant names and menu items\n",
    "def generate_restaurant_info(country):\n",
    "    # Create a prompt for restaurant name generation\n",
    "    name_prompt = PromptTemplate(\n",
    "        input_variables=[\"country\"],\n",
    "        template=\"Generate a creative restaurant name for a restaurant in {country}.\"\n",
    "    )\n",
    "\n",
    "    # Create a prompt for menu item generation\n",
    "    menu_prompt = PromptTemplate(\n",
    "        input_variables=[\"country\"],\n",
    "        template=\"Generate a list of popular menu items for a restaurant in {country}.\"\n",
    "    )\n",
    "\n",
    "    # Generate restaurant name\n",
    "    restaurant_name = llm(name_prompt.format(country=country))\n",
    "\n",
    "    # Generate menu items\n",
    "    menu_items = llm(menu_prompt.format(country=country))\n",
    "\n",
    "    return restaurant_name, menu_items\n",
    "\n",
    "# Set up the Streamlit interface\n",
    "st.title(\"Restaurant Name and Menu Generator\")  # Set the title of the Streamlit app\n",
    "country = st.text_input(\"Enter a country:\")  # Create a text input field for the user to enter a country\n",
    "\n",
    "if st.button(\"Generate\"):  # Create a button that triggers the generation process\n",
    "    if country:  # Check if the user has entered a country\n",
    "        restaurant_name, menu_items = generate_restaurant_info(country)  # Generate restaurant name and menu items\n",
    "        st.subheader(\"Generated Restaurant Name:\")  # Display a subheader for the restaurant name\n",
    "        st.write(restaurant_name)  # Display the generated restaurant name\n",
    "        st.subheader(\"Suggested Menu Items:\")  # Display a subheader for the menu items\n",
    "        st.write(menu_items)  # Display the generated menu items\n",
    "    else:\n",
    "        st.warning(\"Please enter a country.\")  # Display a warning if no country is entered\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
